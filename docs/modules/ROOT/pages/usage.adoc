= Usage

== Authentication
Every user has to authenticate themselves before using Superset.
There are multiple options to set up the authentication of users.

=== Webinterface
The default setting is to manually set up users via the Webinterface.

=== LDAP
Superset supports authentication of users against an LDAP server.
Have a look at https://github.com/stackabletech/superset-operator/blob/main/examples/superset-with-ldap.yaml[the LDAP example] and the general xref:commons-operator::authenticationclass.adoc[Stackable Authentication] documentation on how to set it up.
In general, it requires you to specify a xref:commons-operator::authenticationclass.adoc[`AuthenticationClass`] which is used to authenticate the users. In this example we assign all the users the `Admin` role once they log into Superset.

[source,yaml]
----
apiVersion: superset.stackable.tech/v1alpha1
kind: SupersetCluster
metadata:
  name: superset-with-ldap-server-veri-tls
spec:
  image:
    productVersion: 1.5.1
    stackableVersion: 3.0.0
  [...]
  authenticationConfig:
    authenticationClass: superset-with-ldap-server-veri-tls-ldap
    userRegistrationRole: Admin
----

== Authorization
Superset has a concept called `Roles` which allows you to grant user permissions based on roles.
Have a look at the https://superset.apache.org/docs/security[Superset documentation on Security].

=== Webinterface
You can see all the available roles in the Webinterface of Superset.
You can view all the available roles in the Webinterface of Superset and can also assign users to these roles.

=== LDAP
Superset supports assigning roles to users based on their LDAP group membership.
This is not supported yet.
Currently all the users logging in via LDAP get assigned the same role which you can configure via the attribute `authenticationConfig.userRegistrationRole` on the `SupersetCluster` object.

== Connecting Apache Druid Clusters

The operator can automatically connect Superset to Apache Druid clusters managed by the https://docs.stackable.tech/druid/index.html[Stackable Druid Cluster].

To do so, create a `DruidConnection` resource:

[source,yaml]
----
apiVersion: superset.stackable.tech/v1alpha1
kind: DruidConnection
metadata:
  name: superset-druid-connection
spec:
  superset:
    name: superset
    namespace: default
  druid:
    name: my-druid-cluster
    namespace: default

----

The `name` and `namespace` in `spec.superset` refer to the Superset cluster that you want to connect. Following our example above, the name is `superset`.

In `spec.druid` you specify the `name` and `namespace` of your Druid cluster.

The `namespace` part is optional; if it is omitted it will default to the namespace of the DruidConnection.

The namespace for the Superset and Druid cluster can be omitted, in that case the Operator will assume that they are in the same namespace as the DruidConnection.

Once the database is initialized, the connection will be added to the cluster by the operator. You can see it in the user interface under Data > Databases:

image::superset-databases.png[Superset databases showing the connected Druid cluster]

== Monitoring

The managed Superset instances are automatically configured to export Prometheus metrics. See
xref:home:operators:monitoring.adoc[] for more details.

== Configuration & Environment Overrides

The cluster definition also supports overriding configuration properties and environment variables,
either per role or per role group, where the more specific override (role group) has precedence over
the less specific one (role).

IMPORTANT: Overriding certain properties which are set by the operator (such as the `STATS_LOGGER`)
can interfere with the operator and can lead to problems.

=== Configuration Properties

For a role or role group, at the same level of `config`, you can specify `configOverrides` for the
`superset_config.py`. For example, if you want to set the CSV export encoding and the preferred
databases adapt the `nodes` section of the cluster resource like so:

[source,yaml]
----
nodes:
  roleGroups:
    default:
      config: {}
      configOverrides:
        superset_config.py:
          CSV_EXPORT: "{'encoding': 'utf-8'}"
          PREFERRED_DATABASES: |-
            [
                'PostgreSQL',
                'Presto',
                'MySQL',
                'SQLite',
                # etc.
            ]
----

Just as for the `config`, it is possible to specify this at the role level as well:

[source,yaml]
----
nodes:
  configOverrides:
    superset_config.py:
      CSV_EXPORT: "{'encoding': 'utf-8'}"
      PREFERRED_DATABASES: |-
        [
            'PostgreSQL',
            'Presto',
            'MySQL',
            'SQLite',
            # etc.
        ]
  roleGroups:
    default:
      config: {}
----

All override property values must be strings. They are treated as Python expressions. So care must
be taken to not produce an invalid configuration.

For a full list of configuration options we refer to the
https://github.com/apache/superset/blob/master/superset/config.py[main config file for Superset].

=== Environment Variables

In a similar fashion, environment variables can be (over)written. For example per role group:

[source,yaml]
----
nodes:
  roleGroups:
    default:
      config: {}
      envOverrides:
        FLASK_ENV: development
----

or per role:

[source,yaml]
----
nodes:
  envOverrides:
    FLASK_ENV: development
  roleGroups:
    default:
      config: {}
----

// cliOverrides don't make sense for this operator, so the feature is omitted for now

=== Storage for data volumes

The Superset operator currently does not support using https://kubernetes.io/docs/concepts/storage/persistent-volumes[PersistentVolumeClaims] for internal storage.

=== Resource Requests

// The "nightly" version is needed because the "include" directive searches for
// files in the "stable" version by default.
// TODO: remove the "nightly" version after the next platform release (current: 22.09)
include::nightly@home:concepts:stackable_resource_requests.adoc[]

If no resource requests are configured explicitly, the Superset operator uses the following defaults:

[source,yaml]
----
nodes:
  roleGroups:
    default:
      config:
        resources:
          cpu:
            min: '200m'
            max: "4"
          memory:
            limit: '2Gi'
----

WARNING: The default values are _most likely_ not sufficient to run a proper cluster in production. Please adapt according to your requirements.
